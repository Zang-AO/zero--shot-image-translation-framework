ğŸ‰ ZSXT Web UI - START HERE
=============================

## âš¡ Quick Launch (30 seconds)

```bash
python run_ui.py
```

**Browser opens automatically to:** http://localhost:8501

---

## ğŸš€ Launch Options

### Option 1: Python Launcher (Recommended)
```bash
python run_ui.py
```
âœ… Checks dependencies  
âœ… Validates model paths  
âœ… Shows helpful messages  

### Option 2: Direct Streamlit
```bash
streamlit run app.py
```
âœ… Direct launch  
âœ… Full control  

### Option 3: Windows Batch
```
Double-click: start_ui.bat
```
âœ… One-click on Windows  

### Option 4: Unix/Linux/Mac
```bash
bash start_ui.sh
```
âœ… One-click on Unix systems  

---

## ğŸ“– Documentation Map

| Document | Purpose | Read Time |
|----------|---------|-----------|
| **README.md** | Project overview & features | 5 min |
| **UI_GUIDE.md** | Complete UI documentation | 15 min |
| **QUICK_REFERENCE.md** | Quick lookup guide | 2 min |
| **QUICKSTART.md** | Step-by-step usage | 10 min |
| **COMPLETION_REPORT.md** | Implementation details | 10 min |

---

## ğŸ¨ Web UI Features

### ğŸ  Quick Start Tab
- Project overview
- Model status
- Feature highlights

### ğŸ“¸ Single Image Tab
- Upload image
- Real-time preview
- One-click translate
- Download result

### ğŸ“ Batch Processing Tab
- Select folder
- Batch translate
- View metrics
- Download all results

### â„¹ï¸ Information Tab
- Model architecture
- Parameter details
- Performance metrics
- Citations

---

## âœ… Verification Checklist

Before first launch, verify:

```bash
# 1. Check Python environment
python verify_env.py
# Should show: âœ… All checks passed!

# 2. Check dependencies
pip list | grep streamlit
# Should show: streamlit (>=1.28.0)

# 3. Check GPU (optional)
python -c "import torch; print('GPU:', torch.cuda.is_available())"
```

---

## ğŸ¯ Common Tasks

### Process Single Image
1. Open Web UI
2. Click "ğŸ“¸ Single Image" tab
3. Click "ğŸ“¤ Upload Image"
4. Select image file
5. Click "Process" button
6. Click "ğŸ“¥ Download Result"

### Batch Process Folder
1. Open Web UI
2. Click "ğŸ“ Batch Processing" tab
3. Click "ğŸ“ Select Folder"
4. Choose folder with images
5. Click "ğŸš€ Start Batch Processing"
6. Wait for progress bar
7. Click "ğŸ“¦ Download All Results"

### Use Custom Model
1. Click device/config menu (top-right)
2. Expand "âš™ï¸ Advanced Settings"
3. Enter custom model path
4. Click "Load Model"
5. New model is ready to use

### Check GPU Status
1. Look at sidebar (right side)
2. See "ğŸ’» System Information"
3. Shows GPU name and memory usage

---

## âš¡ Performance Tips

| Setting | Speed | Memory | Best For |
|---------|-------|--------|----------|
| GPU Mode | ğŸš€ Fast | ~2GB | Production |
| CPU Mode | ğŸ¢ Slow | ~500MB | Testing |
| Batch Size 1 | ğŸ“Š Balanced | ~1GB | Memory-limited |
| Batch Size 3 | âš¡ Fast | ~2GB | Powerful GPU |

---

## ğŸ†˜ Common Issues

### "Port 8501 already in use"
```bash
streamlit run app.py --server.port 8502
```

### "CUDA out of memory"
1. Switch to CPU mode in sidebar
2. Or close other GPU applications
3. Or reduce batch size

### "Model checkpoint not found"
1. Ensure `checkpoints/gen_best.pth` exists
2. Or specify custom path in sidebar
3. Or download from releases

### "Dependencies not installed"
```bash
pip install -r requirements.txt --upgrade
python verify_env.py
```

---

## ğŸ“± System Requirements

- **CPU**: Minimum i5 (Recommended i7+)
- **GPU**: NVIDIA with CUDA 11.0+ (Optional)
- **RAM**: 8GB+ for GPU, 4GB+ for CPU
- **Disk**: 50GB free space
- **Browser**: Chrome, Firefox, Safari, Edge
- **Python**: 3.8 or higher

---

## ğŸŒ Access from Other Devices

To access UI from another computer on same network:

```bash
# Start UI with network access
streamlit run app.py --server.address 0.0.0.0

# From another device, visit:
http://<your-ip>:8501
```

---

## ğŸ“Š File Structure

```
_code_EN/
â”œâ”€â”€ ğŸ¨ UI Files
â”‚   â”œâ”€â”€ app.py                 Main interface
â”‚   â”œâ”€â”€ run_ui.py              Python launcher
â”‚   â”œâ”€â”€ start_ui.bat           Windows launcher
â”‚   â””â”€â”€ start_ui.sh            Unix launcher
â”œâ”€â”€ ğŸ“š Docs
â”‚   â”œâ”€â”€ README.md              Main docs
â”‚   â”œâ”€â”€ UI_GUIDE.md            UI documentation
â”‚   â”œâ”€â”€ QUICK_REFERENCE.md     Quick guide
â”‚   â””â”€â”€ QUICKSTART.md          Getting started
â”œâ”€â”€ ğŸš€ Scripts
â”‚   â”œâ”€â”€ train.py               Training
â”‚   â”œâ”€â”€ inference.py           Inference
â”‚   â””â”€â”€ verify_env.py          Setup check
â””â”€â”€ ğŸ’¾ Data
    â”œâ”€â”€ config.yaml            Settings
    â”œâ”€â”€ checkpoints/           Models
    â””â”€â”€ datasets/              Data
```

---

## ğŸ”— Quick Links

- **GitHub**: [ZSXT Repository](#)
- **Documentation**: See README.md
- **Issues**: Report problems here
- **Contributing**: Help us improve!

---

## ğŸ’¡ Pro Tips

1. **Faster Processing**: Use GPU mode
2. **Better Quality**: Try different models in checkpoints/
3. **Batch Processing**: Process multiple images at once
4. **Custom Models**: Load your own trained models
5. **Multiple Runs**: Results saved automatically

---

## ğŸ“ First Time Users

1. âœ… Read **README.md** (5 min)
2. âœ… Run `python verify_env.py` (1 min)
3. âœ… Launch with `python run_ui.py` (1 min)
4. âœ… Try **Single Image** tab (2 min)
5. âœ… Try **Batch Processing** tab (5 min)
6. âœ… Check **Information** tab (2 min)
7. âœ… Read **UI_GUIDE.md** for advanced features (15 min)

**Total Time**: ~30 minutes to master the UI

---

## â“ FAQ

**Q: Do I need GPU?**  
A: No, CPU works fine. GPU is just faster (10-50ms vs 100-500ms).

**Q: Can I use my own model?**  
A: Yes! Specify model path in sidebar, click "Load Model".

**Q: How do I save results?**  
A: UI provides one-click download after processing.

**Q: Can I process folders with thousands of images?**  
A: Yes! Batch processing handles any number.

**Q: Is there a command-line version?**  
A: Yes, use `python inference.py` for CLI mode.

**Q: How do I train my own model?**  
A: Use `python train.py` with config.yaml settings.

---

## ğŸ“ Support

If you encounter issues:

1. Check **QUICK_REFERENCE.md** â†’ Troubleshooting
2. Check **UI_GUIDE.md** â†’ Troubleshooting
3. Run `python verify_env.py` for diagnostics
4. Check project GitHub issues

---

**Ready to start?**

```bash
python run_ui.py
```

Then visit: http://localhost:8501

Enjoy! ğŸš€

---

**Version**: 1.0.0  
**Updated**: 2025-11-30
